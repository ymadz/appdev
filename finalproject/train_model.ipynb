{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a2a0888",
   "metadata": {},
   "source": [
    "# ‚öΩ FIFA Player Dashboard with Machine Learning\n",
    "\n",
    "This project is a web-based dashboard built with Django that uses a machine learning model (XGBoost Regressor) to predict FIFA players‚Äô overall ratings. It visualizes player statistics, allows exploration by position, and evaluates model performance using real data.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dataset Overview\n",
    "\n",
    "- **Source**: [FIFA 21 dataset from Kaggle](https://www.kaggle.com/stefanoleone992/fifa-21-complete-player-dataset)\n",
    "- **Records**: ~18,000 player entries\n",
    "- **Features Used**:\n",
    "  - Age, Height, Weight\n",
    "  - In-game stats: Pace, Shooting, Passing, Dribbling, Defending, Physic\n",
    "  - Categorical: Preferred Foot, Work Rate, Player Positions\n",
    "- **Target**: `overall` (overall rating)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Preprocessing Steps\n",
    "\n",
    "1. **Handling Missing Values**:\n",
    "   - Rows missing key numeric or target fields were dropped.\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - `preferred_foot`: Encoded as binary (Right = 1, Left = 0)\n",
    "   - `work_rate` and `player_positions`: Encoded using simple hashing\n",
    "   - All features scaled naturally (XGBoost handles scaling internally)\n",
    "\n",
    "3. **Splitting Data**:\n",
    "   - `train_test_split` (80/20 ratio)\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ Model Architecture\n",
    "\n",
    "- **Model Used**: `XGBoost Regressor`\n",
    "- **Reason**: Efficient with tabular data, handles missing values, good out-of-the-box performance\n",
    "- **Parameters**: Default `XGBRegressor()` settings for initial development\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Training Results\n",
    "\n",
    "| Metric         | Score |\n",
    "|----------------|-------|\n",
    "| Train RMSE     | ~2.34 |\n",
    "| Test RMSE      | ~2.35 |\n",
    "| Train R¬≤ Score | 0.89  |\n",
    "| Test R¬≤ Score  | 0.88  |\n",
    "| Bias-Variance Status | Good Fit (Low Bias, Low Variance) |\n",
    "\n",
    "> Note: These values are dynamically calculated and may vary slightly depending on the random train-test split.\n",
    "\n",
    "---\n",
    "\n",
    "## üîí Authentication\n",
    "\n",
    "Authentication was added using Django‚Äôs built-in authentication system:\n",
    "\n",
    "- Users must log in to access the dashboard\n",
    "- `/login/`, `/logout/`, and `/register/` routes were created\n",
    "- `@login_required` decorator used to protect dashboard views\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Integration Steps\n",
    "\n",
    "1. **Model Training**:  \n",
    "   Train `XGBRegressor` on selected features and save using `joblib`:\n",
    "\n",
    "   ```python\n",
    "   from xgboost import XGBRegressor\n",
    "   from joblib import dump\n",
    "\n",
    "   model = XGBRegressor()\n",
    "   model.fit(X_train, y_train)\n",
    "   dump(model, 'xgboost_fifa_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97143a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Training Performance:\n",
      "   RMSE: 1.06\n",
      "   R¬≤:   0.9768\n",
      "\n",
      "üìà Testing Performance:\n",
      "   RMSE: 1.47\n",
      "   R¬≤:   0.9569\n",
      "\n",
      "üìã Bias-Variance Check:\n",
      "‚úÖ Bias-variance is balanced\n",
      "\n",
      "‚úÖ Model saved as 'xgboost_fifa_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\madz\\Documents\\GitHub\\appdev\\playerperformance\\datasets\\players_15.csv\")\n",
    "\n",
    "# Drop rows with missing essential features or target\n",
    "df = df.dropna(subset=['overall', 'preferred_foot', 'work_rate', 'player_positions'])\n",
    "\n",
    "# Simplify player positions\n",
    "def simplify_position(pos):\n",
    "    if any(p in pos for p in ['CB', 'LB', 'RB', 'LWB', 'RWB', 'CDM']):\n",
    "        return 'DEF'\n",
    "    elif any(p in pos for p in ['CM', 'CAM', 'RM', 'LM']):\n",
    "        return 'MID'\n",
    "    else:\n",
    "        return 'ATT'\n",
    "\n",
    "df['player_position_group'] = df['player_positions'].apply(simplify_position)\n",
    "\n",
    "# Encode categorical features\n",
    "le_foot = LabelEncoder()\n",
    "df['preferred_foot_enc'] = le_foot.fit_transform(df['preferred_foot'])\n",
    "\n",
    "le_work = LabelEncoder()\n",
    "df['work_rate_enc'] = le_work.fit_transform(df['work_rate'])\n",
    "\n",
    "le_pos = LabelEncoder()\n",
    "df['position_group_enc'] = le_pos.fit_transform(df['player_position_group'])\n",
    "\n",
    "# Define features and target\n",
    "features = ['age', 'height_cm', 'weight_kg', 'pace', 'shooting', 'passing',\n",
    "            'dribbling', 'defending', 'physic',\n",
    "            'preferred_foot_enc', 'work_rate_enc', 'position_group_enc']\n",
    "target = 'overall'\n",
    "\n",
    "# Apply IQR filtering for numeric features\n",
    "numeric_features = ['age', 'height_cm', 'weight_kg', 'pace', 'shooting', 'passing',\n",
    "                    'dribbling', 'defending', 'physic']\n",
    "\n",
    "for feature in numeric_features:\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[feature] >= lower_bound) & (df[feature] <= upper_bound)]\n",
    "\n",
    "# Split data\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost model\n",
    "model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "preds = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, preds) ** 0.5\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "# Evaluate on training set\n",
    "train_preds = model.predict(X_train)\n",
    "train_rmse = mean_squared_error(y_train, train_preds) ** 0.5\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nüìä Training Performance:\")\n",
    "print(f\"   RMSE: {train_rmse:.2f}\")\n",
    "print(f\"   R¬≤:   {train_r2:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Testing Performance:\")\n",
    "print(f\"   RMSE: {rmse:.2f}\")\n",
    "print(f\"   R¬≤:   {r2:.4f}\")\n",
    "\n",
    "# Bias-variance insight\n",
    "print(\"\\nüìã Bias-Variance Check:\")\n",
    "if abs(train_r2 - r2) > 0.15:\n",
    "    if train_r2 > r2:\n",
    "        print(\"‚ö†Ô∏è High variance detected (potential overfitting)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è High bias detected (potential underfitting)\")\n",
    "else:\n",
    "    print(\"‚úÖ Bias-variance is balanced\")\n",
    "\n",
    "# Save model\n",
    "with open(\"xgboost_fifa_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"\\n‚úÖ Model saved as 'xgboost_fifa_model.pkl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
